{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import tracemalloc\n",
    "import psutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from decision_tree_classifier import DecisionTreeClassifier\n",
    "import scienceplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use([\"grid\", \"notebook\", \"science\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"dataset.csv\")\n",
    "\n",
    "X, y = df.iloc[:, 1:-1], df.iloc[:, -1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm\n",
       "145            6.7           3.0            5.2           2.3\n",
       "146            6.3           2.5            5.0           1.9\n",
       "147            6.5           3.0            5.2           2.0\n",
       "148            6.2           3.4            5.4           2.3\n",
       "149            5.9           3.0            5.1           1.8"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145    Iris-virginica\n",
       "146    Iris-virginica\n",
       "147    Iris-virginica\n",
       "148    Iris-virginica\n",
       "149    Iris-virginica\n",
       "Name: Species, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PetalLengthCm    3.051976e-91\n",
       "PetalWidthCm     4.376957e-85\n",
       "SepalLengthCm    1.669669e-31\n",
       "SepalWidthCm     1.327917e-16\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_features = SelectKBest(f_classif, k=4).fit(X, y)\n",
    "p_values = pd.Series(best_features.pvalues_)\n",
    "p_values.index = X.columns\n",
    "\n",
    "p_values.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = X.to_numpy(), y.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(test, predictions):\n",
    "    return (np.sum(test == predictions) / len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stratified_kfold = StratifiedKFold(n_splits=5, random_state=3, shuffle=True)\n",
    "\n",
    "results_entropy = []\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(stratified_kfold.split(X, y)):\n",
    "    X_train, y_train = X[train_index], y[train_index]\n",
    "    X_test, y_test = X[test_index], y[test_index]\n",
    "    dt = DecisionTreeClassifier()\n",
    "    dt.fit(X_train, y_train)\n",
    "    y_pred = dt.predict(X_test)\n",
    "    results_entropy.append({\n",
    "        \"accuracy\": accuracy(y_test, y_pred),\n",
    "        \"confusion_matrix\": confusion_matrix(y_test, y_pred),\n",
    "        \"classification_report\": classification_report(y_test, y_pred)\n",
    "    })\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "stratified_kfold = StratifiedKFold(n_splits=5, random_state=3, shuffle=True)\n",
    "\n",
    "results_gini = []\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(stratified_kfold.split(X, y)):\n",
    "    X_train, y_train = X[train_index], y[train_index]\n",
    "    X_test, y_test = X[test_index], y[test_index]\n",
    "    dt = DecisionTreeClassifier(criterion=\"gini\")\n",
    "    dt.fit(X_train, y_train)\n",
    "    y_pred = dt.predict(X_test)\n",
    "    results_gini.append({\n",
    "        \"accuracy\": accuracy(y_test, y_pred),\n",
    "        \"confusion_matrix\": confusion_matrix(y_test, y_pred),\n",
    "        \"classification_report\": classification_report(y_test, y_pred)\n",
    "    })"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_gini_df = pd.DataFrame(results_gini)\n",
    "results_entropy_df = pd.DataFrame(results_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>confusion_matrix</th>\n",
       "      <th>classification_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.866667</td>\n",
       "      <td>[[10, 0, 0], [0, 8, 2], [0, 2, 8]]</td>\n",
       "      <td>precision    recall  f1-score...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.933333</td>\n",
       "      <td>[[9, 1, 0], [0, 10, 0], [0, 1, 9]]</td>\n",
       "      <td>precision    recall  f1-score...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.900000</td>\n",
       "      <td>[[10, 0, 0], [0, 8, 2], [0, 1, 9]]</td>\n",
       "      <td>precision    recall  f1-score...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>[[10, 0, 0], [0, 10, 0], [0, 0, 10]]</td>\n",
       "      <td>precision    recall  f1-score...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>[[10, 0, 0], [0, 9, 1], [0, 0, 10]]</td>\n",
       "      <td>precision    recall  f1-score...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy                      confusion_matrix  \\\n",
       "0  0.866667    [[10, 0, 0], [0, 8, 2], [0, 2, 8]]   \n",
       "1  0.933333    [[9, 1, 0], [0, 10, 0], [0, 1, 9]]   \n",
       "2  0.900000    [[10, 0, 0], [0, 8, 2], [0, 1, 9]]   \n",
       "3  1.000000  [[10, 0, 0], [0, 10, 0], [0, 0, 10]]   \n",
       "4  0.966667   [[10, 0, 0], [0, 9, 1], [0, 0, 10]]   \n",
       "\n",
       "                               classification_report  \n",
       "0                   precision    recall  f1-score...  \n",
       "1                   precision    recall  f1-score...  \n",
       "2                   precision    recall  f1-score...  \n",
       "3                   precision    recall  f1-score...  \n",
       "4                   precision    recall  f1-score...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_gini_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = [[0, 0, 0], [0, 0, 0], [0, 0, 0]]\n",
    "\n",
    "for confusion_matrix in results_gini_df[\"confusion_matrix\"]:\n",
    "    matrix[0][0] += confusion_matrix[0][0]\n",
    "    matrix[0][1] += confusion_matrix[0][1]\n",
    "    matrix[0][2] += confusion_matrix[0][2]\n",
    "    matrix[1][0] += confusion_matrix[1][0]\n",
    "    matrix[1][1] += confusion_matrix[1][1]\n",
    "    matrix[1][2] += confusion_matrix[1][2]\n",
    "    matrix[2][0] += confusion_matrix[2][0]\n",
    "    matrix[2][1] += confusion_matrix[2][1]\n",
    "    matrix[2][2] += confusion_matrix[2][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[49, 1, 0], [0, 45, 5], [0, 4, 46]]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00        10\n",
      "Iris-versicolor       0.80      0.80      0.80        10\n",
      " Iris-virginica       0.80      0.80      0.80        10\n",
      "\n",
      "       accuracy                           0.87        30\n",
      "      macro avg       0.87      0.87      0.87        30\n",
      "   weighted avg       0.87      0.87      0.87        30\n",
      "\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      0.90      0.95        10\n",
      "Iris-versicolor       0.83      1.00      0.91        10\n",
      " Iris-virginica       1.00      0.90      0.95        10\n",
      "\n",
      "       accuracy                           0.93        30\n",
      "      macro avg       0.94      0.93      0.93        30\n",
      "   weighted avg       0.94      0.93      0.93        30\n",
      "\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00        10\n",
      "Iris-versicolor       0.89      0.80      0.84        10\n",
      " Iris-virginica       0.82      0.90      0.86        10\n",
      "\n",
      "       accuracy                           0.90        30\n",
      "      macro avg       0.90      0.90      0.90        30\n",
      "   weighted avg       0.90      0.90      0.90        30\n",
      "\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00        10\n",
      "Iris-versicolor       1.00      1.00      1.00        10\n",
      " Iris-virginica       1.00      1.00      1.00        10\n",
      "\n",
      "       accuracy                           1.00        30\n",
      "      macro avg       1.00      1.00      1.00        30\n",
      "   weighted avg       1.00      1.00      1.00        30\n",
      "\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00        10\n",
      "Iris-versicolor       1.00      0.90      0.95        10\n",
      " Iris-virginica       0.91      1.00      0.95        10\n",
      "\n",
      "       accuracy                           0.97        30\n",
      "      macro avg       0.97      0.97      0.97        30\n",
      "   weighted avg       0.97      0.97      0.97        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for classification_report in results_gini_df[\"classification_report\"]:\n",
    "    print(classification_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_gini_df[\"accuracy\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>confusion_matrix</th>\n",
       "      <th>classification_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.866667</td>\n",
       "      <td>[[10, 0, 0], [0, 8, 2], [0, 2, 8]]</td>\n",
       "      <td>precision    recall  f1-score...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>[[10, 0, 0], [0, 10, 0], [0, 1, 9]]</td>\n",
       "      <td>precision    recall  f1-score...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.900000</td>\n",
       "      <td>[[10, 0, 0], [0, 8, 2], [0, 1, 9]]</td>\n",
       "      <td>precision    recall  f1-score...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>[[10, 0, 0], [0, 9, 1], [0, 0, 10]]</td>\n",
       "      <td>precision    recall  f1-score...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>[[10, 0, 0], [0, 9, 1], [0, 0, 10]]</td>\n",
       "      <td>precision    recall  f1-score...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy                     confusion_matrix  \\\n",
       "0  0.866667   [[10, 0, 0], [0, 8, 2], [0, 2, 8]]   \n",
       "1  0.966667  [[10, 0, 0], [0, 10, 0], [0, 1, 9]]   \n",
       "2  0.900000   [[10, 0, 0], [0, 8, 2], [0, 1, 9]]   \n",
       "3  0.966667  [[10, 0, 0], [0, 9, 1], [0, 0, 10]]   \n",
       "4  0.966667  [[10, 0, 0], [0, 9, 1], [0, 0, 10]]   \n",
       "\n",
       "                               classification_report  \n",
       "0                   precision    recall  f1-score...  \n",
       "1                   precision    recall  f1-score...  \n",
       "2                   precision    recall  f1-score...  \n",
       "3                   precision    recall  f1-score...  \n",
       "4                   precision    recall  f1-score...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_entropy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = [[0, 0, 0], [0, 0, 0], [0, 0, 0]]\n",
    "\n",
    "for confusion_matrix in results_entropy_df[\"confusion_matrix\"]:\n",
    "    matrix[0][0] += confusion_matrix[0][0]\n",
    "    matrix[0][1] += confusion_matrix[0][1]\n",
    "    matrix[0][2] += confusion_matrix[0][2]\n",
    "    matrix[1][0] += confusion_matrix[1][0]\n",
    "    matrix[1][1] += confusion_matrix[1][1]\n",
    "    matrix[1][2] += confusion_matrix[1][2]\n",
    "    matrix[2][0] += confusion_matrix[2][0]\n",
    "    matrix[2][1] += confusion_matrix[2][1]\n",
    "    matrix[2][2] += confusion_matrix[2][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[50, 0, 0], [0, 44, 6], [0, 4, 46]]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_entropy_df[\"accuracy\"].mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime = []\n",
    "\n",
    "for _ in range(100):\n",
    "    start = time.perf_counter()\n",
    "    dt.fit(X_train, y_train)\n",
    "    stop = time.perf_counter()\n",
    "    runtime.append((stop - start) * 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime_df = pd.DataFrame(runtime, columns=[\"Milliseconds\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Milliseconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>51.533961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.582829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>45.249300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>48.522125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>50.479250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>52.532775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>79.680400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Milliseconds\n",
       "count    100.000000\n",
       "mean      51.533961\n",
       "std        5.582829\n",
       "min       45.249300\n",
       "25%       48.522125\n",
       "50%       50.479250\n",
       "75%       52.532775\n",
       "max       79.680400"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runtime_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime = []\n",
    "\n",
    "for _ in range(100):\n",
    "    start = time.perf_counter()\n",
    "    dt.predict(X_test)\n",
    "    stop = time.perf_counter()\n",
    "    runtime.append((stop - start) * 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Milliseconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.045439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.016640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.035700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.036400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.038200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.046750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.143100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Milliseconds\n",
       "count    100.000000\n",
       "mean       0.045439\n",
       "std        0.016640\n",
       "min        0.035700\n",
       "25%        0.036400\n",
       "50%        0.038200\n",
       "75%        0.046750\n",
       "max        0.143100"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runtime_df = pd.DataFrame(runtime, columns=[\"Milliseconds\"])\n",
    "runtime_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first_size=0, first_peak=0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "first_size, first_peak = tracemalloc.get_traced_memory()\n",
    "tracemalloc.reset_peak()\n",
    "print(f\"{first_size=}, {first_peak=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4781, 18933)\n"
     ]
    }
   ],
   "source": [
    "tracemalloc.start()\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)\n",
    "print(tracemalloc.get_traced_memory())\n",
    "\n",
    "\n",
    "tracemalloc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c261aea317cc0286b3b3261fbba9abdec21eaa57589985bb7a274bf54d6cc0a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
